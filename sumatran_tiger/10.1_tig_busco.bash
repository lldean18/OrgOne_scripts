#!/bin/bash
# Laura Dean
# 9/1/25
# for running on the UoN HPC Ada

#SBATCH --partition=defq
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=100g
#SBATCH --time=12:00:00
#SBATCH --job-name=tig_busco
#SBATCH --output=/gpfs01/home/mbzlld/code_and_scripts/slurm_out_scripts/slurm-%x-%j.out

# set variables
species=sumatran_tiger # set the species
wkdir=/gpfs01/home/mbzlld/data/OrgOne/$species # set the working directory
#assembly_dir=raft_hifiasm_asm4
#assembly_dir=${species}_flye_asm4
#assembly_dir=raft_hifiasm_asm9
#assembly_dir=hifiasm_asm5
#assembly_dir=hifiasm_asm8
#assembly_dir=hifiasm_asm9
#assembly_dir=hifiasm_asm10
assembly_dir=hifiasm_asm11

#assembly=assembly.fasta # all assemblies generated by flye are called this by default
#assembly=finalasm.bp.p_ctg.fasta # all assemblies generated by my raft / hifiasm pipeline should be called this
#assembly=ONTasm.bp.p_ctg.fasta # assemblies generated by testing of the new hifiasm version were named this
assembly=ONTasm.bp.p_ctg_100kb.fasta # same assembly but filtered to remove fragments smaller than 100kb
#lineage_dataset=laurasiatheria_odb10 # for bactrian camel
#lineage_dataset=primates_odb10 # for western chimpanzee
lineage_dataset=carnivora_odb10 # for sumatran tiger

# load your bash profile for using conda
source $HOME/.bash_profile

# load conda environment
conda activate busco

# decide what lineage dataset you will use for your species
#busco --list-datasets

# run busco
# --in : input assembly in fasta format
# --lineage_dataset nearest class in the busco database for your species
# --mode specify you are working on a genome assembly
# --out name the output files (busco will create a dfolder with this name)
# --out_path specify the path to your desired output directory
# --cpu specify number of cores to use
busco \
--in $wkdir/$assembly_dir/$assembly \
--lineage_dataset $lineage_dataset \
--mode genome \
--out buscos_${assembly%.*} \
--out_path $wkdir/$assembly_dir \
--cpu 8

# deactivate conda
conda deactivate





